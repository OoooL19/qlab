{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data as a .csv file (exported directly from Qualtrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Child Studies Questionnaire_021419.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary columns. This is written so that one can easily identify column titles and remove it from the column drop line of code below to keep the column if wanted. This code first removes unnecessary columns and then removes one index row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = df.drop(['StartDate', 'EndDate','Status','IPAddress','Progress','Duration (in seconds)','Finished','RecordedDate','ResponseId','RecipientLastName','RecipientFirstName','RecipientEmail','ExternalReference','LocationLatitude','LocationLongitude','DistributionChannel','UserLanguage','Q3','Q4','Q6','Q7','Q8','Q14','Q14_4_TEXT','Q15','Q15_3_TEXT','Q16_1','Q16_2','Q16_3','Q16_4','Q17','Q18','Q19','Q20','Q21','Q22','Q23','Q23_1_TEXT','Q24','Q24_1_TEXT','Q25','Q25_1_TEXT','Q26','Q26_1_TEXT','Q34_1_1','Q34_1_2','Q34_2_1','Q34_2_2','Q34_3_1','Q34_3_2','Q34_4_1','Q34_4_2','Q35','Q39','Q40'], axis=1)\n",
    "df_correct = df_correct.drop([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to determine whether the participant is monolingual or bilingual. Therefore, if a parent wrote \"native\" or \"fluent\" in more than one language, the participant is noted as bilingual in a newly created column 'Language History' otherwise they are monolingual. Once this new column is created, we remove all the columns with language history information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct['Q28_1_3'] = df_correct['Q28_1_3'].str.replace('fluent','native')\n",
    "df_correct['Q28_2_3'] = df_correct['Q28_2_3'].str.replace('fluent','native')\n",
    "df_correct['language_history'] = pd.np.where(df_correct.Q28_1_3.str.contains(\"native\", case=False) & df_correct.Q28_2_3.str.contains(\"native\"), \"bilingual\",\"monolingual\")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = df_correct.drop(columns=['Q28_1_1','Q28_1_2','Q28_1_3','Q28_1_4','Q28_2_1','Q28_2_2','Q28_2_3','Q28_2_4','Q28_3_1','Q28_3_2','Q28_3_3','Q28_3_4','Q29_1_TEXT','Q29_2_TEXT'])\n",
    "                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute an average of left or right handedness. Across all 10 items evaluating handedness, we replace anything that parents scored as the child using their right hand with a '1'. Anything else gets a 0. An average is then computed into a new column 'Handedness'. A score of .5 would indicate the child is equally comfortable using their right and left hands. We then delete these 10 columns of individual handedness data and save the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct.loc[df_correct['Q41_1'].str.contains('right',na=False), 'Q41_1'] = 1\n",
    "df_correct.loc[df_correct['Q41_2'].str.contains('right',na=False), 'Q41_2'] = 1\n",
    "df_correct.loc[df_correct['Q41_3'].str.contains('right',na=False), 'Q41_3'] = 1\n",
    "df_correct.loc[df_correct['Q41_4'].str.contains('right',na=False), 'Q41_4'] = 1\n",
    "df_correct.loc[df_correct['Q41_5'].str.contains('right',na=False), 'Q41_5'] = 1\n",
    "df_correct.loc[df_correct['Q41_6'].str.contains('right',na=False), 'Q41_6'] = 1\n",
    "df_correct.loc[df_correct['Q41_7'].str.contains('right',na=False), 'Q41_7'] = 1\n",
    "df_correct.loc[df_correct['Q41_8'].str.contains('right',na=False), 'Q41_8'] = 1\n",
    "df_correct.loc[df_correct['Q41_9'].str.contains('right',na=False), 'Q41_9'] = 1\n",
    "df_correct.loc[df_correct['Q41_10'].str.contains('right',na=False), 'Q41_10'] = 1\n",
    "\n",
    "#df_correct.columns.get_loc('Q41_10')\n",
    "\n",
    "df_average= df_correct.iloc[:,27:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average = df_average.convert_objects(convert_numeric=True)\n",
    "df_average = df_average.fillna(0)\n",
    "df_correct['handedness']=df_average.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = df_correct.drop(columns=['Q41_1','Q41_2','Q41_3','Q41_4','Q41_5','Q41_6','Q41_7','Q41_8','Q41_9','Q41_10','Q38_1','Q38_2','Q38_3','Q38_4','Q38_5','Q42'])\n",
    "df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct.to_csv('Child Demographic Output_021419.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
